{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "BASE_DIR = os.path.dirname('./')\n",
    "ROOT_DIR = os.path.dirname(BASE_DIR)\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "import yaml\n",
    "import logging\n",
    "\n",
    "from lib.helpers.dataloader_helper import build_dataloader\n",
    "from lib.helpers.model_helper import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3060\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "mode = 'test' # test, eval, train\n",
    "config = 'lib/kitti.yaml'\n",
    "\n",
    "def create_logger(log_file):\n",
    "    log_format = '%(asctime)s  %(levelname)5s  %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_format, filename=log_file)\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    console.setFormatter(logging.Formatter(log_format))\n",
    "    logging.getLogger(__name__).addHandler(console)\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "\n",
    "# load cfg\n",
    "assert (os.path.exists(config))\n",
    "cfg = yaml.load(open(config, 'r'), Loader=yaml.Loader)\n",
    "os.makedirs(cfg['trainer']['log_dir'], exist_ok=True)\n",
    "logger = create_logger(os.path.join(cfg['trainer']['log_dir'], 'train.log'))\n",
    "cfg['dataset']['batch_size'] = 1\n",
    "\n",
    "import shutil\n",
    "if mode != 'eval':\n",
    "    if not mode != 'test':\n",
    "        if os.path.exists(os.path.join(cfg['trainer']['log_dir'], 'lib/')):\n",
    "            shutil.rmtree(os.path.join(cfg['trainer']['log_dir'], 'lib/'))\n",
    "    if not mode != 'test':\n",
    "        shutil.copytree('./lib', os.path.join(cfg['trainer']['log_dir'], 'lib/'))\n",
    "    \n",
    "\n",
    "#  build dataloader\n",
    "train_loader, val_loader, test_loader = build_dataloader(cfg['dataset'])\n",
    "\n",
    "# build model\n",
    "model = build_model(cfg['model'], train_loader.dataset.cls_mean_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class detectionInfo(object):\n",
    "    def __init__(self, line):\n",
    "        #print('line: name=%s truncated=%f occluded=%f alpha=%f\\n bbox=[%f %f %f %f]\\n dimensions=[%f %f %f]\\n location=[%f %f %f]\\n rotation_y=%f score=%f' % (line[0], npline[0], npline[1], npline[2], npline[3], npline[4], npline[5], npline[6], npline[7], npline[8], npline[9], npline[10], npline[11], npline[12], npline[13], npline[14]))\n",
    "\n",
    "        self.name = line[0]\n",
    "\n",
    "        self.truncation = np.float64(line[1])\n",
    "        self.occlusion = int(line[2])\n",
    "\n",
    "        # local orientation = alpha + pi/2\n",
    "        self.alpha = np.float64(line[3])\n",
    "\n",
    "        # in pixel coordinate\n",
    "        self.xmin = int(line[4])\n",
    "        self.ymin = int(line[5])\n",
    "        self.xmax = int(line[6])\n",
    "        self.ymax = int(line[7])\n",
    "\n",
    "        # height, weigh, length in object coordinate, meter\n",
    "        self.h = np.float64(line[8])\n",
    "        self.w = np.float64(line[9])\n",
    "        self.l = np.float64(line[10])\n",
    "\n",
    "        # x, y, z in camera coordinate, meter\n",
    "        self.tx = np.float64(line[11])\n",
    "        self.ty = np.float64(line[12])\n",
    "        self.tz = np.float64(line[13])\n",
    "\n",
    "        # global orientation [-pi, pi]\n",
    "        self.rot_global = np.float64(line[14])\n",
    "\n",
    "        # score\n",
    "        self.score = np.float64(line[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_birdviewbox(obj, shape, scale):\n",
    "    h = obj.h * scale\n",
    "    w = obj.w * scale\n",
    "    l = obj.l * scale\n",
    "    x = obj.tx * scale\n",
    "    y = obj.ty * scale\n",
    "    z = obj.tz * scale\n",
    "    rot_y = obj.rot_global\n",
    "\n",
    "    R = np.array([[-np.cos(rot_y), np.sin(rot_y)],\n",
    "                  [np.sin(rot_y), np.cos(rot_y)]])\n",
    "    t = np.array([x, z]).reshape(1, 2).T\n",
    "\n",
    "    x_corners = [0, l, l, 0]  # -l/2\n",
    "    z_corners = [w, w, 0, 0]  # -w/2\n",
    "\n",
    "    x_corners += -w / 2\n",
    "    z_corners += -l / 2\n",
    "\n",
    "    # bounding box in object coordinate\n",
    "    corners_2D = np.array([x_corners, z_corners])\n",
    "    # rotate\n",
    "    corners_2D = R.dot(corners_2D)\n",
    "    # translation\n",
    "    corners_2D = t - corners_2D\n",
    "    # in camera coordinate\n",
    "    corners_2D[0] += int(shape/2)\n",
    "    corners_2D = (corners_2D).astype(np.int16)\n",
    "    corners_2D = corners_2D.T\n",
    "\n",
    "    return np.vstack((corners_2D, corners_2D[0,:]))\n",
    "\n",
    "def draw_birdeyes(ax2, obj, shape, color):\n",
    "    scale = 15\n",
    "    pred_corners_2d = compute_birdviewbox(obj, shape, scale)\n",
    "    codes = [Path.LINETO] * pred_corners_2d.shape[0]\n",
    "    codes[0] = Path.MOVETO\n",
    "    codes[-1] = Path.CLOSEPOLY\n",
    "    pth = Path(pred_corners_2d, codes)\n",
    "    p = patches.PathPatch(pth, fill=False, color=color)\n",
    "    ax2.add_patch(p)\n",
    "\n",
    "def draw_2Dbox(ax, obj, color):\n",
    "    xmin = obj.xmin\n",
    "    xmax = obj.xmax\n",
    "    ymin = obj.ymin\n",
    "    ymax = obj.ymax\n",
    "    width = xmax - xmin\n",
    "    height = ymax - ymin\n",
    "\n",
    "    ax.add_patch(patches.Rectangle((xmin, ymin), width, height, fill=False, color='red'))\n",
    "\n",
    "def compute_3Dbox(P2, obj):\n",
    "    R = np.array([[np.cos(obj.rot_global), 0, np.sin(obj.rot_global)],\n",
    "                  [0, 1, 0],\n",
    "                  [-np.sin(obj.rot_global), 0, np.cos(obj.rot_global)]])\n",
    "\n",
    "    x_corners = [0, obj.l, obj.l, obj.l, obj.l, 0, 0, 0]  # -l/2\n",
    "    y_corners = [0, 0, obj.h, obj.h, 0, 0, obj.h, obj.h]  # -h\n",
    "    z_corners = [0, 0, 0, obj.w, obj.w, obj.w, obj.w, 0]  # -w/2\n",
    "\n",
    "    x_corners = [i - obj.l / 2 for i in x_corners]\n",
    "    y_corners = [i - obj.h for i in y_corners]\n",
    "    z_corners = [i - obj.w / 2 for i in z_corners]\n",
    "\n",
    "    corners_3D = np.array([x_corners, y_corners, z_corners])\n",
    "    corners_3D = R.dot(corners_3D)\n",
    "    corners_3D += np.array([obj.tx, obj.ty, obj.tz]).reshape((3, 1))\n",
    "\n",
    "    corners_3D_1 = np.vstack((corners_3D, np.ones((corners_3D.shape[-1]))))\n",
    "    corners_2D = P2.dot(corners_3D_1)\n",
    "    corners_2D = corners_2D / corners_2D[2]\n",
    "    corners_2D = corners_2D[:2]\n",
    "\n",
    "    return corners_2D\n",
    "\n",
    "def draw_3Dbox(ax, P2, obj, color):\n",
    "    corners_2D = compute_3Dbox(P2, obj)\n",
    "\n",
    "    # draw all lines through path\n",
    "    # https://matplotlib.org/users/path_tutorial.html\n",
    "    bb3d_lines_verts_idx = [0, 1, 2, 3, 4, 5, 6, 7, 0, 5, 4, 1, 2, 7, 6, 3]\n",
    "    bb3d_on_2d_lines_verts = corners_2D[:, bb3d_lines_verts_idx]\n",
    "    verts = bb3d_on_2d_lines_verts.T\n",
    "    codes = [Path.LINETO] * verts.shape[0]\n",
    "    codes[0] = Path.MOVETO\n",
    "    # codes[-1] = Path.CLOSEPOLYq\n",
    "    pth = Path(verts, codes)\n",
    "    p = patches.PathPatch(pth, fill=False, color=color, linewidth=2)\n",
    "\n",
    "    width = corners_2D[:, 3][0] - corners_2D[:, 1][0]\n",
    "    height = corners_2D[:, 2][1] - corners_2D[:, 1][1]\n",
    "    # put a mask on the front\n",
    "    front_fill = patches.Rectangle((corners_2D[:, 1]), width, height, fill=True, color=color, alpha=0.4)\n",
    "    ax.add_patch(p)\n",
    "    ax.add_patch(front_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(image, calib, detections, drawBird):\n",
    "    P2 = calib[0].P2\n",
    "\n",
    "    fig = plt.figure(figsize=(20.00, 5.12), dpi=100)\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    gs = GridSpec(1, 4)\n",
    "    gs.update(wspace=0)  # set the spacing between axes.\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, :3])\n",
    "    if drawBird:\n",
    "        ax2 = fig.add_subplot(gs[0, 3:])\n",
    "\n",
    "    shape = 900\n",
    "\n",
    "    for line_p in detections:\n",
    "        obj = detectionInfo(line_p)\n",
    "        truncated = np.abs(float(obj.truncation))\n",
    "        occluded = np.abs(float(obj.occlusion))\n",
    "        trunc_level = 255\n",
    "\n",
    "        # truncated object in dataset is not observable\n",
    "        if truncated < trunc_level:\n",
    "            color = 'green'\n",
    "            if obj.name == 'Cyclist':\n",
    "                color = 'yellow'\n",
    "            elif obj.name == 'Pedestrian':\n",
    "                color = 'cyan'\n",
    "            \n",
    "            #draw_2Dbox(ax, obj, color)\n",
    "            draw_3Dbox(ax, P2, obj, color)\n",
    "            if drawBird:\n",
    "                draw_birdeyes(ax2, obj, shape, color)\n",
    "\n",
    "    # visualize 3D bounding box\n",
    "    ax.imshow(image)\n",
    "    ax.set_xticks([]) #remove axis value\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    if drawBird:\n",
    "        birdimage = np.zeros((shape, shape, 3), np.uint8)\n",
    "        # plot camera view range\n",
    "        x1 = np.linspace(0, shape / 2)\n",
    "        x2 = np.linspace(shape / 2, shape)\n",
    "        ax2.plot(x1, shape / 2 - x1, ls='--', color='grey', linewidth=1, alpha=0.5)\n",
    "        ax2.plot(x2, x2 - shape / 2, ls='--', color='grey', linewidth=1, alpha=0.5)\n",
    "        ax2.plot(shape / 2, 0, marker='+', markersize=16, markeredgecolor='red')\n",
    "\n",
    "        # visualize bird eye view\n",
    "        ax2.imshow(birdimage, origin='lower')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:12:31,759   INFO  ==> Loading from checkpoint './checkpoints/model.pth'\n",
      "2024-10-11 15:12:32,053   INFO  ==> Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mode\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from lib.helpers.save_helper import load_checkpoint\n",
    "from lib.helpers.decode_helper import extract_dets_from_outputs\n",
    "from lib.helpers.decode_helper import decode_detections\n",
    "from lib.datasets.kitti_utils import get_affine_transform\n",
    "\n",
    "class PrintHelper(object):\n",
    "    def __init__(self, data_loader):\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "    def getPrintables(self, idx):\n",
    "        dataset = self.data_loader.dataset\n",
    "\n",
    "        img = dataset.get_image(idx)\n",
    "        calibs = [dataset.get_calib(idx)]\n",
    "        \n",
    "        \n",
    "        return idx, img, calibs, dataset.resolution, dataset.downsample, dataset.mean, dataset.std, dataset.cls_mean_size\n",
    "\n",
    "\n",
    "class Printer(object):\n",
    "    def __init__(self, cfg, model, logger):\n",
    "        self.cfg = cfg\n",
    "        self.model = model\n",
    "\n",
    "        self.logger = logger\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        if self.cfg.get('resume_model', None):\n",
    "            load_checkpoint(\n",
    "                model = self.model,\n",
    "                optimizer = None,\n",
    "                filename = cfg['resume_model'],\n",
    "                logger = self.logger,\n",
    "                map_location=self.device\n",
    "            )\n",
    "        \n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def print(self, idx, img, calibs, resolution, downsample, mean, std, cls_mean_size):\n",
    "        img_size = np.array(img.size)\n",
    "\n",
    "        center = np.array(img_size) / 2\n",
    "        crop_size = img_size\n",
    "        coord_range = np.array([center-crop_size/2,center+crop_size/2]).astype(np.float32)\n",
    "\n",
    "        trans, trans_inv = get_affine_transform(center, crop_size, 0, resolution, inv=1)\n",
    "        inputs = img.transform(tuple(resolution.tolist()),\n",
    "                            method=Image.AFFINE,\n",
    "                            data=tuple(trans_inv.reshape(-1).tolist()),\n",
    "                            resample=Image.BILINEAR)\n",
    "        inputs = np.array(inputs).astype(np.float32) / 255.0\n",
    "        #inputs = (inputs - mean) / std\n",
    "        inputs = inputs.transpose(2, 0, 1)  # C * H * W\n",
    "\n",
    "        features_size = resolution // downsample\n",
    "        info = {'img_id': np.asarray([idx]),\n",
    "                'img_size': np.asarray([img_size]),\n",
    "                'bbox_downsample_ratio': np.asarray([img_size/features_size])}\n",
    "        \n",
    "        torch.set_grad_enabled(False)\n",
    "        inputs = torch.Tensor(inputs).unsqueeze(0).to(self.device)\n",
    "        calib = torch.Tensor(calibs[0].P2).unsqueeze(0).to(self.device)\n",
    "        coord_ranges = torch.Tensor(coord_range).unsqueeze(0).to(self.device)\n",
    "        outputs = self.model(inputs, coord_ranges, calib, K=50, mode='test')\n",
    "\n",
    "        dets = extract_dets_from_outputs(outputs=outputs, K=50)\n",
    "        dets = dets.detach().cpu().numpy()\n",
    "        # get corresponding calibs & transform tensor to numpy\n",
    "        info = {key: val for key, val in info.items()}\n",
    "\n",
    "        dets = decode_detections(\n",
    "            dets = dets,\n",
    "            info = info,\n",
    "            calibs = calibs,\n",
    "            cls_mean_size=cls_mean_size,\n",
    "            threshold = self.cfg['threshold']\n",
    "        )\n",
    "        dets = dets[idx]\n",
    "        preds = []\n",
    "        class_map = {\n",
    "            0: 'Pedestrian', \n",
    "            1: 'Car', \n",
    "            2: 'Cyclist'\n",
    "        }\n",
    "\n",
    "        for d in dets:\n",
    "            cls = class_map[d[0]]\n",
    "            tmp = [cls, 0.0, 0]\n",
    "            tmp.extend(d[1:])\n",
    "            preds.append(tmp)\n",
    "\n",
    "        return preds\n",
    "\n",
    "# evaluation mode\n",
    "printer = Printer(cfg['tester'], model, logger)\n",
    "if mode == 'eval':\n",
    "    print('evaluation mode')\n",
    "    printHelper = PrintHelper(val_loader)\n",
    "elif mode == 'test':\n",
    "    print('test mode')\n",
    "    printHelper = PrintHelper(test_loader)\n",
    "else:\n",
    "    print('train mode')\n",
    "    printHelper = PrintHelper(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "(384, 1280, 3)\n",
      "[[   0.    0.]\n",
      " [1280.  384.]]\n",
      "0:00:00.059090\n"
     ]
    }
   ],
   "source": [
    "print(idx)\n",
    "torch.cuda.synchronize() # Wait for all kernels in all streams on a CUDA device to complete.\n",
    "start_time = timer()\n",
    "\n",
    "for x in range(1):\n",
    "    idx, img, calibs, resolution, downsample, mean, std, cls_mean_size = printHelper.getPrintables(idx)\n",
    "    print(np.shape(img))\n",
    "    preds = printer.print(idx, img, calibs, resolution, downsample, mean, std, cls_mean_size)\n",
    "\n",
    "    #visualization(img, calibs, preds, False)\n",
    "    idx = idx +1\n",
    "\n",
    "torch.cuda.synchronize() # Wait for all kernels in all streams on a CUDA device to complete.\n",
    "end_time = timer()\n",
    "print(timedelta(seconds=end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monolss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
